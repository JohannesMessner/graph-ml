{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "devoted-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.utils import from_networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-assumption",
   "metadata": {},
   "source": [
    "# Generating a cycle dataset\n",
    "\n",
    "Here we generate a dataset containing pairs of graphs that are not distinguishable by the 1-WL isomorphism test.\n",
    "Later we will use GNNs to learn to tell them apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "respected-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_nx = []\n",
    "graphs_is_cycle = []  # keeps track if a graph is a cycle or disjoint\n",
    "for n in range(6, 16):\n",
    "    g_cyc = nx.Graph()\n",
    "    g_cyc.add_nodes_from(range(n))\n",
    "    g_cyc.add_edges_from([(x, x+1) for x in range(n-1)] + [(n-1, 0)])  # connect nodes to cycle\n",
    "    \n",
    "    for split_n in range(3,n-2):\n",
    "        g_split = nx.Graph()\n",
    "        g_cyc.add_nodes_from(range(n))\n",
    "        g_split.add_edges_from([(x, x+1) for x in range(split_n-1)] + [(split_n-1, 0)])  # first cycle of size split_n\n",
    "        g_split.add_edges_from([(x, x+1) for x in range(split_n, n-1)] + [(n-1, split_n)])  # dsecond cycle of remaing nodes\n",
    "        graphs_nx.append(g_split)\n",
    "        graphs_is_cycle.append(False)\n",
    "        graphs_nx.append(g_cyc)  # add g_cyc every time to maintain balance\n",
    "        graphs_is_cycle.append(True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modified-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the graphs to torch_geometric.data.Data objects\n",
    "graphs = [from_networkx(g) for g in graphs_nx]\n",
    "for i_g, g in enumerate(graphs):\n",
    "    g.x = torch.zeros((g.num_nodes, 50))  # uniform x/features\n",
    "    g.y = torch.tensor([1 if graphs_is_cycle[i_g] else 0])  # target label indicating whether graph is cycle or disjoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-shower",
   "metadata": {},
   "source": [
    "# Building a GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "corporate-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom message passing layer\n",
    "#class CustomLayer(geom_nn.MessagePassing):\n",
    "    #def __init__(self, in_channels, out_channels):\n",
    "        #super().__init__(aggr='add')\n",
    "        #self.lin = nn.Linear(in_channels, out_channels)\n",
    "        #self.activation = nn.ReLU()\n",
    "        \n",
    "    # activation, linear etc probably goes here\n",
    "    #def forward(self, x, edge_index):\n",
    "        #return self.propagate(edge_index, x=x)\n",
    "    \n",
    "    # stuff that happens after all the message passing, so just id??\n",
    "    #def update(self, x):\n",
    "        #return self.activation(self.linear(x))\n",
    "        \n",
    "    # this looks fine\n",
    "    #def message(self, x_j):\n",
    "        #return x_j\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, depth, mp_layer=None):\n",
    "        super().__init__()\n",
    "        # the type of message passing layer used throughout the net\n",
    "        self.mp_layer = geom_nn.GCNConv if mp_layer is None else mp_layer\n",
    "        self.pool = geom_nn.global_mean_pool\n",
    "        self.mp_layers = nn.ModuleList()\n",
    "        \n",
    "        # standard mlp used after message passing layers\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        # add message passing layers\n",
    "        self.mp_layers.append(self.mp_layer(input_dim, hidden_dim))\n",
    "        for i in range(depth-1):\n",
    "            self.mp_layers.append(self.mp_layer(hidden_dim, hidden_dim))\n",
    "            \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        for l in self.mp_layers:\n",
    "            x = l(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.pool(x, batch)\n",
    "        x = self.post_mp(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, label):\n",
    "        return torch.nn.functional.binary_cross_entropy(pred, label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "sensitive-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, nb_epochs=50, rni=False, lr=0.01, test_data=None):\n",
    "    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    if rni:\n",
    "        model = RNINet(dataset[0].num_node_features, 50, 1, 16)\n",
    "    else:\n",
    "        model = Net(dataset[0].num_node_features, 50, 1, 16)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(nb_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch).flatten()\n",
    "            label = batch.y.to(torch.float32)\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        if not test_data is None:\n",
    "            if epoch % 10 == 0:\n",
    "                test_acc = test(model, test_data)\n",
    "                print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(epoch, total_loss, test_acc))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "synthetic-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset):\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    tot = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            pred = model(data).flatten()\n",
    "            label = data.y\n",
    "            pred = [0 if p <= 0.5 else 1 for p in pred]  # 0 if prediction <= 0.5, 1 othwerwise\n",
    "            correct_i = np.equal(pred, label)\n",
    "            correct += np.array(correct_i).sum().item()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "criminal-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(data, k=5, **kwargs):\n",
    "    # We perform k-fold cross validation\n",
    "    chunks = []\n",
    "    chunk_size = int(len(data)/k)\n",
    "    # split the data\n",
    "    for i in range(k):\n",
    "        if i*chunk_size+chunk_size <= len(data):\n",
    "            chunks.append(data[i*chunk_size:(i+1)*chunk_size])\n",
    "        else:\n",
    "            chunks.append(data[i*chunk_size:])\n",
    "    # perform training and testing\n",
    "    accuracies = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        test_set = chunk\n",
    "        train_set = [x for l in (chunks[0:i] + chunks[i+1:]) for x in l]\n",
    "        model = train(train_set, **kwargs)\n",
    "        acc = test(model, test_set)\n",
    "        accuracies.append(acc)\n",
    "        print('Accuracy at test-chunk {}: {}'.format(i, acc))\n",
    "    return np.array(accuracies).sum() / len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "angry-saturn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at test-chunk 0: 0.5\n",
      "Accuracy at test-chunk 1: 0.5\n",
      "Accuracy at test-chunk 2: 0.5\n",
      "Accuracy at test-chunk 3: 0.5\n",
      "Accuracy at test-chunk 4: 0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# we exprect a test accuracy of 0.5, since these types of graphs can't be distinguished by the net\n",
    "avg_acc = cross_validate(graphs)\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "missing-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes 50% of node fearures randomly, to increase expressive power\n",
    "class RNINet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, depth, mp_layer=None):\n",
    "        super().__init__()\n",
    "        # the type of message passing layer used throughout the net\n",
    "        self.mp_layer = geom_nn.GCNConv if mp_layer is None else mp_layer\n",
    "        self.pool = geom_nn.global_mean_pool\n",
    "        self.mp_layers = nn.ModuleList()\n",
    "        \n",
    "        # standard mlp used after message passing layers\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        # add message passing layers\n",
    "        self.mp_layers.append(self.mp_layer(input_dim, hidden_dim))\n",
    "        for i in range(depth-1):\n",
    "            self.mp_layers.append(self.mp_layer(hidden_dim, hidden_dim))\n",
    "            \n",
    "    def rni(self, x):\n",
    "        init_len = len(x[0])\n",
    "        random_len = int(len(x[0])/2)\n",
    "        random_samples = torch.normal(mean=0, std=1, size=(len(x), random_len))\n",
    "        x_half = x.transpose(0,1)[init_len-random_len:].transpose(0,1)\n",
    "        x_rni = torch.cat((x_half,random_samples), 1)\n",
    "        assert len(x_rni[0]) == init_len\n",
    "        return x_rni\n",
    "            \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # RNI\n",
    "        x = self.rni(x)\n",
    "        for l in self.mp_layers:\n",
    "            x = l(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.pool(x, batch)\n",
    "        x = self.post_mp(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, label):\n",
    "        return torch.nn.functional.binary_cross_entropy(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "therapeutic-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 2.0795. Test accuracy: 0.5000\n",
      "Epoch 10. Loss: 2.0727. Test accuracy: 0.5000\n",
      "Epoch 20. Loss: 2.0832. Test accuracy: 0.5000\n",
      "Epoch 30. Loss: 2.0812. Test accuracy: 0.5000\n",
      "Epoch 40. Loss: 2.0779. Test accuracy: 0.5000\n",
      "Epoch 50. Loss: 2.0757. Test accuracy: 0.5000\n",
      "Epoch 60. Loss: 2.0749. Test accuracy: 0.5000\n",
      "Epoch 70. Loss: 2.0815. Test accuracy: 0.5000\n",
      "Epoch 80. Loss: 2.0573. Test accuracy: 0.5000\n",
      "Epoch 90. Loss: 2.0637. Test accuracy: 0.5000\n",
      "Epoch 100. Loss: 2.0158. Test accuracy: 0.6818\n",
      "Epoch 110. Loss: 2.0014. Test accuracy: 0.8182\n",
      "Epoch 120. Loss: 1.9460. Test accuracy: 0.5909\n",
      "Epoch 130. Loss: 1.9411. Test accuracy: 0.5909\n",
      "Epoch 140. Loss: 1.9185. Test accuracy: 0.5909\n",
      "Epoch 150. Loss: 1.7162. Test accuracy: 0.4091\n",
      "Epoch 160. Loss: 1.7870. Test accuracy: 0.7273\n",
      "Epoch 170. Loss: 1.8048. Test accuracy: 0.5455\n",
      "Epoch 180. Loss: 1.6966. Test accuracy: 0.6818\n",
      "Epoch 190. Loss: 1.7480. Test accuracy: 0.6818\n",
      "Epoch 200. Loss: 1.7930. Test accuracy: 0.7727\n",
      "Epoch 210. Loss: 1.6587. Test accuracy: 0.7273\n",
      "Epoch 220. Loss: 2.0048. Test accuracy: 0.5909\n",
      "Epoch 230. Loss: 1.8786. Test accuracy: 0.5909\n",
      "Epoch 240. Loss: 1.5685. Test accuracy: 0.9091\n",
      "Epoch 250. Loss: 1.4687. Test accuracy: 0.5455\n",
      "Epoch 260. Loss: 1.4575. Test accuracy: 0.6818\n",
      "Epoch 270. Loss: 1.7701. Test accuracy: 0.7273\n",
      "Epoch 280. Loss: 1.4508. Test accuracy: 0.7273\n",
      "Epoch 290. Loss: 1.5511. Test accuracy: 0.4545\n"
     ]
    }
   ],
   "source": [
    "# train with RNI. We expect the accuracy to go up, since expressive power of the model was increased\n",
    "model = train(graphs[:int(0.8*len(graphs))], nb_epochs=300, rni=True, lr=0.0001, test_data=graphs[int(0.8*len(graphs)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "conservative-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at test-chunk 0: 0.6818181818181818\n",
      "Accuracy at test-chunk 1: 0.9090909090909091\n",
      "Accuracy at test-chunk 2: 0.6363636363636364\n",
      "Accuracy at test-chunk 3: 0.6818181818181818\n",
      "Accuracy at test-chunk 4: 0.6818181818181818\n",
      "0.718181818181818\n"
     ]
    }
   ],
   "source": [
    "avg_acc = cross_validate(graphs, rni=True, nb_epochs=300, lr=0.0001)\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-benefit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
